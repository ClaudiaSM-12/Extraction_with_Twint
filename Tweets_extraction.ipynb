{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_tweet = [\"#KeikoNova\", \"#keikonuncamas\", \"#FujimoriNuncaMás\", \"#NoAKeiko\", \"#Keikino\", \"#KeikoTAPERdiendo\",\n",
    "              \"#GolpeElectoral\",\"#FuerzaPopular\", \"#ConMiVotoNoTeMetas\",\n",
    "               \"#BICENTENARIOMEJORCONSTITUCION\", \"#FujimafiaNuncaMás\", \"#NoAlNarcoEstado\", \"#FujimorismoNuncaMas\",\n",
    "               \"#KeikoGolpistaYDictadora\", \"#keikonoimpugnesmiacta\", \"#KEIKOMENTIROSA\", \"#KeikoPresidenta2021\",\n",
    "               \"#KeikoPresidenta\",\"#PedroCastilloPresidente\",\"#PedroCastilloNoVa\", \"#NoAlComunismoEnElPeru\",\n",
    "               \"#NoAlTerrorismo\", \"#NoAlComunismo\",\"#LosBuenosSomosMas\",\"#pedrocastilloNICagando\", \"#PedroCastilloNoVa\", \n",
    "              \"#PedroTiraPiedras\",\"#Genocidas\",\"#KeikoPresidenta2021\",\"#KeikoFujimori\",\"#CastilloMachistayHomofobico\",\n",
    "              \"#CastilloYCerronUnSoloCorazon\",\"#EleccionesPerú2021\",\"#DefiendeTuVoto\",\"#RespetaMiVoto\",\"#LaMaldiciondelaSenoraK\",\n",
    "              \"#LaCamisetaNoSeMancha\",\"#FujimorismoNuncaMás\",\"#SegundaVuelta\", \"#EleccionesBicentenario\",\"#Elecciones2021PE\",\n",
    "               \"#PeruDecide2021\",\"#PedroCastillo\",\"#KeikoFujimori\",\"#Elecciones2021\",\"#eleccionesperu\",\"#ONPE\",\"#EleccionesPeru\", \n",
    "              \"#Elecciones2021Peru\",\"#EleccionesBicentenario\", \"#Onpe\",\"ONPE\",\"#JNE\",\"#SegundaVuelta\", \n",
    "              \"#ONPEPeru\",\"#JNEPeru\",\"#PeruLibre\",\"#PERULIBRE\",\"#TerrorismoNuncaMas\",\"#Jne\", \"#PedroCastilloTe\", \"#JNE_Peru\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_tweet1 = [\"#KeikoNova\",\"#SegundaVuelta\",\"#PedroCastilloTe\",'#NoAlNarcoEstado','#RespetaMiVoto',\n",
    "       '#KeikoPresidenta','#FujimafiaNuncaMas',\"#pedrocastilloNiCagando\",'#KEIKOMENTIROSA',\n",
    "       '#PedroCastilloNoVa','#DefiendeTuVoto','#DefiendeTuVoto','#PedroCastilloPresidente',\n",
    "       '#keikonuncamas','#BICENTENARIOMEJORCONSTITUCION','#NoAKeiko','#KeikoTAPERdiendo','#CastilloYCerronUnSoloCorazon',\n",
    "       '#NoalTerrorismo','#KeikoGolpistaYDictadora','#NoAlComunismoEnElPeru','#PeruDecide2021',\n",
    "       '#FujimoriNuncaMas','#LosBuenosSomosMas','#KeikoFujimori','#FujimorismoNuncaMas','#Genocidas',\n",
    "       '#NoAlComunismo','#PeruLibre','#PedroCastillo','#Elecciones2021','#TerrorismoNuncaMas']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"#KeikoNova\",\"#SegundaVuelta\",\"#PedroCastilloTe\",'#NoAlNarcoEstado','#RespetaMiVoto',\n",
    "       '#KeikoPresidenta','#FujimafiaNuncaMas',\"#pedrocastilloNiCagando\",'#KEIKOMENTIROSA',\n",
    "       '#PedroCastilloNoVa','#DefiendeTuVoto','#DefiendeTuVoto','#PedroCastilloPresidente',\n",
    "       '#keikonuncamas','#BICENTENARIOMEJORCONSTITUCION','#NoAKeiko','#KeikoTAPERdiendo','#CastilloYCerronUnSoloCorazon',\n",
    "       '#NoalTerrorismo','#KeikoGolpistaYDictadora','#NoAlComunismoEnElPeru','#PeruDecide2021',\n",
    "       '#FujimoriNuncaMas','#LosBuenosSomosMas','#KeikoFujimori','#FujimorismoNuncaMas','#FujimorismoNuncaMás','#Genocidas',\n",
    "       '#NoAlComunismo','#PeruLibre','#PedroCastillo','#Elecciones2021','#TerrorismoNuncaMas','#FuerzaPopular','#FujimoriNuncaMás',\n",
    "       'KeikoFujimori','PedroCastillo','keiko','castillo','EleccionesPresidenciales2021','JNE','ONPE','Derecha','Izquierda','DebatePresidencial','#Rojos']\n",
    "\n",
    "tag_vac = ['#VacúnateYa','#COVID19', '#PongoElHombro', '#LaVacunaEsVida', '#NoBajemosLaGuardia', '#VamosaSalirAdelante', '#vacunacion',\n",
    "           '#sialavacuna', '#VacunaFest','#TodasLasVacunasSirven', '#NuevaCepa', '#Sinopharm', '#YoApoyoaBeto', '#ErnestoBustamante',\n",
    "           '#SagastiGenocida', '#VacunaCOVID19', '#SuizaLab', '#AstraZeneca', '#Pfizer', '#delta', '#variante', '#PfizerBiontech', \n",
    "           '#Moderna', '#CureVac']\n",
    "tag_vac2 = ['#VacunacionPeru',\n",
    "           '#sialavacuna', '#VacunaFest','#TodasLasVacunasSirven', '#NuevaCepa', '#Sinopharm', '#YoApoyoaBeto', '#ErnestoBustamante',\n",
    "           '#SagastiGenocida', '#VacunaCOVID19', '#SuizaLab', '#AstraZeneca', '#Pfizer', '#delta', '#variante', '#PfizerBiontech', \n",
    "           '#Moderna', '#CureVac']\n",
    "tag_vac1 = ['#VacunateYa']\n",
    "tag2 = ['#MirthaVásquez','#Premier','#GabineteVásquez' ,'#GuidoBellido','@patriciagamarra']\n",
    "tag_vacunacion = [\"#VacunacionPeru\", \"#MinisterioDeSaludPerú\",  \"#VacunaCOVID19\", '#VacúnateYa', '#COVID19', '#Vacunación', 'Vacunagate', \n",
    "                  '#VacúnateYa','#COVID19', '#PongoElHombro', '#LaVacunaEsVida', '#NoBajemosLaGuardia', '#VamosaSalirAdelante', '#vacunacion',\n",
    "           '#sialavacuna', '#VacunaFest','#TodasLasVacunasSirven', '#NuevaCepa', '#Sinopharm', '#ErnestoBustamante',\n",
    "           '#SagastiGenocida', '#SuizaLab', '#AstraZeneca', '#Pfizer', '#delta', '#variante', '#PfizerBiontech', \n",
    "           '#Moderna', '#CureVac']\n",
    "tag_vacunacion_1 = ['#NoBajemosLaGuardia', '#VamosaSalirAdelante', '#vacunacion',\n",
    "           '#sialavacuna', '#VacunaFest','#TodasLasVacunasSirven', '#NuevaCepa', '#Sinopharm', '#ErnestoBustamante',\n",
    "           '#SagastiGenocida', '#SuizaLab', '#AstraZeneca', '#Pfizer', '#delta', '#variante', '#PfizerBiontech', \n",
    "           '#Moderna', '#CureVac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crear_carpeta(Rutabase, name_carpeta):\n",
    "    # Se define el nombre de la carpeta o directorio a crear\n",
    "    directorio = Rutabase + name_carpeta\n",
    "    if os.path.exists(directorio):\n",
    "        shutil.rmtree(directorio)\n",
    "        os.makedirs(directorio)\n",
    "        print(\"Se reemplazo el directorio %s \" % directorio)\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directorio)\n",
    "        except OSError:\n",
    "            print(\"La creación del directorio %s falló\" % directorio)\n",
    "        else:\n",
    "            print(\"Se ha creado el directorio: %s \" % directorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Buscar_Palabra(cadena, palabra_incluida):\n",
    "    lista_cadenas = [cadena]\n",
    "    #print(cadena.find(palabra_incluida))\n",
    "    if cadena.find(palabra_incluida) < 0:\n",
    "        lista_cadenas.append(palabra_incluida)\n",
    "    return lista_cadenas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Generar_Tweets(lista, Rutabase, since, until):\n",
    "    lista = pd.unique(lista)\n",
    "    df_Final = pd.DataFrame()\n",
    "    numero_tweets = 0\n",
    "    for i in lista:\n",
    "        tag = Buscar_Palabra(i,'Peru')\n",
    "        c = twint.Config()\n",
    "        print(tag)\n",
    "        c.Search = tag\n",
    "        c.Language = 'es'\n",
    "        c.Since = since\n",
    "        c.Until = until\n",
    "        c.Limit = 10000\n",
    "        c.Pandas = True\n",
    "        c.Hide_output= True\n",
    "        twint.run.Search(c)\n",
    "        #print(twint.storage.panda.Tweets_df)\n",
    "        df_twint = twint.storage.panda.Tweets_df\n",
    "        print(len(df_twint))\n",
    "        #df_twint = Eliminar_Repetidos(df_twint, 'tweet', 'spanish', 0.5)\n",
    "        #print(df_twint)\n",
    "        #print(len(df_twint))\n",
    "        numero_tweets = numero_tweets + len(df_twint)\n",
    "        Rutarel =  i + '.csv'\n",
    "        Rutasol = os.path.join(Rutabase, Rutarel)\n",
    "        df_twint.to_csv(Rutasol, index = False)\n",
    "        print('Se ha creado correctamente el ' + i + '.csv, recuperando ' + str(numero_tweets) + ' tweets')\n",
    "    #df_Final.to_csv(\"Tweets_prueba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeleccionarTweets(lista, Rutabase):\n",
    "    total_df = pd.DataFrame() \n",
    "    count = 0\n",
    "    for i in lista:\n",
    "        Rutarel =  i + '.csv'\n",
    "        Rutasol = os.path.join(Rutabase, Rutarel)\n",
    "        #print(Rutasol)\n",
    "        df = pd.read_csv(Rutasol, delimiter=',')\n",
    "        #print(df)\n",
    "        new_df = df[df['language'] == 'es']\n",
    "        print('Se ha recuperado ' + str(len(new_df)) + ' tweets en el idioma espanhol')\n",
    "        new_df = new_df.reset_index(drop = True)\n",
    "        new_df = Eliminar_Repetidos(new_df, 'tweet', 'spanish', 0.5)\n",
    "        print('Se han eliminado los repetidos del archivo '+ i +'.csv'+ ' , el nuevo numero de tweets es ' + str(len(new_df)))\n",
    "        #count = count + len(df)\n",
    "        total_df = pd.concat([total_df, new_df],ignore_index=False)\n",
    "    #print(total_df.shape)\n",
    "    total_df = total_df.reset_index(drop = True)\n",
    "    print('Se ha recuperado ' + str(len(total_df)) + ' tweets en total' )\n",
    "    return total_df\n",
    "   \n",
    "#def Eliminar_Reptidos_Archivo(df):\n",
    "    \n",
    "#df[(df['date'] > '2021-04-01') & (df['date'] < '2021-10-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recuperar_Indice(lista_indices):\n",
    "    index = []\n",
    "    for i in lista_indices:\n",
    "        index.append(i[1])\n",
    "    index = pd.unique(index)\n",
    "    index = list(index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eliminar_Repetidos(df, label, language, threshold):\n",
    "    tfidf = TfidfVectorizer(stop_words = stopwords.words(language))\n",
    "    # Construct the TF-IDF matrix\n",
    "    tfidf_matrix = tfidf.fit_transform(df[label])\n",
    "    #print(shape(tfidf_matrix))\n",
    "    # Generate the cosine similarity matrix\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix[:20000])\n",
    "    #print(cosine_sim)\n",
    "    #Lista que recupera los tweets\n",
    "    A = []\n",
    "    for i in range(0,len(cosine_sim)):\n",
    "        for k in range(0,len(cosine_sim)):\n",
    "            if ((k>i) and (cosine_sim[i][k] >= threshold)):\n",
    "                #print(k)\n",
    "                A.append([i,k])\n",
    "                \n",
    "    indices_tweets = Recuperar_Indice(A)\n",
    "    df = df.drop(indices_tweets)\n",
    "    #print(df)\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('Se han recuperado ' + str(len(df)) + ' tweets')\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rutabase = r'C:/Users/USER/Documents/Git/SATwint/'\n",
    "#carpeta = 'data4/'\n",
    "def Obtener_dataset(lista_tweet, name_carpeta, label, language, name):\n",
    "    #Crear_carpeta(Rutabase, name_carpeta)\n",
    "    Ruta = Rutabase + name_carpeta\n",
    "    #Generar_Tweets(lista_tweet, Ruta,'2020-01-01', '2021-11-01')\n",
    "    df = SeleccionarTweets(lista_tweet, Ruta)\n",
    "    #print(df)\n",
    "    #df = Eliminar_Repetidos(df, label, language, 0.5)\n",
    "    #df.to_csv(name + '.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha recuperado 200 tweets en el idioma espanhol\n",
      "Se han recuperado 171 tweets\n",
      "Se han eliminado los repetidos del archivo #VacunacionPeru.csv , el nuevo numero de tweets es 171\n",
      "Se ha recuperado 6 tweets en el idioma espanhol\n",
      "Se han recuperado 6 tweets\n",
      "Se han eliminado los repetidos del archivo #MinisterioDeSaludPerú.csv , el nuevo numero de tweets es 6\n",
      "Se ha recuperado 2960 tweets en el idioma espanhol\n",
      "Se han recuperado 2339 tweets\n",
      "Se han eliminado los repetidos del archivo #VacunaCOVID19.csv , el nuevo numero de tweets es 2339\n",
      "Se ha recuperado 492 tweets en el idioma espanhol\n",
      "Se han recuperado 397 tweets\n",
      "Se han eliminado los repetidos del archivo #VacúnateYa.csv , el nuevo numero de tweets es 397\n",
      "Se ha recuperado 8528 tweets en el idioma espanhol\n",
      "Se han recuperado 5321 tweets\n",
      "Se han eliminado los repetidos del archivo #COVID19.csv , el nuevo numero de tweets es 5321\n",
      "Se ha recuperado 977 tweets en el idioma espanhol\n",
      "Se han recuperado 696 tweets\n",
      "Se han eliminado los repetidos del archivo #Vacunación.csv , el nuevo numero de tweets es 696\n",
      "Se ha recuperado 3421 tweets en el idioma espanhol\n",
      "Se han recuperado 2824 tweets\n",
      "Se han eliminado los repetidos del archivo Vacunagate.csv , el nuevo numero de tweets es 2824\n",
      "Se ha recuperado 492 tweets en el idioma espanhol\n",
      "Se han recuperado 397 tweets\n",
      "Se han eliminado los repetidos del archivo #VacúnateYa.csv , el nuevo numero de tweets es 397\n",
      "Se ha recuperado 8528 tweets en el idioma espanhol\n",
      "Se han recuperado 5321 tweets\n",
      "Se han eliminado los repetidos del archivo #COVID19.csv , el nuevo numero de tweets es 5321\n",
      "Se ha recuperado 5731 tweets en el idioma espanhol\n",
      "Se han recuperado 4031 tweets\n",
      "Se han eliminado los repetidos del archivo #PongoElHombro.csv , el nuevo numero de tweets es 4031\n",
      "Se ha recuperado 77 tweets en el idioma espanhol\n",
      "Se han recuperado 44 tweets\n",
      "Se han eliminado los repetidos del archivo #LaVacunaEsVida.csv , el nuevo numero de tweets es 44\n",
      "Se ha recuperado 3569 tweets en el idioma espanhol\n",
      "Se han recuperado 2921 tweets\n",
      "Se han eliminado los repetidos del archivo #NoBajemosLaGuardia.csv , el nuevo numero de tweets es 2921\n",
      "Se ha recuperado 128 tweets en el idioma espanhol\n",
      "Se han recuperado 113 tweets\n",
      "Se han eliminado los repetidos del archivo #VamosaSalirAdelante.csv , el nuevo numero de tweets es 113\n",
      "Se ha recuperado 976 tweets en el idioma espanhol\n",
      "Se han recuperado 694 tweets\n",
      "Se han eliminado los repetidos del archivo #vacunacion.csv , el nuevo numero de tweets es 694\n",
      "Se ha recuperado 7 tweets en el idioma espanhol\n",
      "Se han recuperado 7 tweets\n",
      "Se han eliminado los repetidos del archivo #sialavacuna.csv , el nuevo numero de tweets es 7\n",
      "Se ha recuperado 523 tweets en el idioma espanhol\n",
      "Se han recuperado 454 tweets\n",
      "Se han eliminado los repetidos del archivo #VacunaFest.csv , el nuevo numero de tweets es 454\n",
      "Se ha recuperado 36 tweets en el idioma espanhol\n",
      "Se han recuperado 36 tweets\n",
      "Se han eliminado los repetidos del archivo #TodasLasVacunasSirven.csv , el nuevo numero de tweets es 36\n",
      "Se ha recuperado 272 tweets en el idioma espanhol\n",
      "Se han recuperado 133 tweets\n",
      "Se han eliminado los repetidos del archivo #NuevaCepa.csv , el nuevo numero de tweets es 133\n",
      "Se ha recuperado 3497 tweets en el idioma espanhol\n",
      "Se han recuperado 2925 tweets\n",
      "Se han eliminado los repetidos del archivo #Sinopharm.csv , el nuevo numero de tweets es 2925\n",
      "Se ha recuperado 46 tweets en el idioma espanhol\n",
      "Se han recuperado 43 tweets\n",
      "Se han eliminado los repetidos del archivo #ErnestoBustamante.csv , el nuevo numero de tweets es 43\n",
      "Se ha recuperado 500 tweets en el idioma espanhol\n",
      "Se han recuperado 421 tweets\n",
      "Se han eliminado los repetidos del archivo #SagastiGenocida.csv , el nuevo numero de tweets es 421\n",
      "Se ha recuperado 20 tweets en el idioma espanhol\n",
      "Se han recuperado 17 tweets\n",
      "Se han eliminado los repetidos del archivo #SuizaLab.csv , el nuevo numero de tweets es 17\n",
      "Se ha recuperado 642 tweets en el idioma espanhol\n",
      "Se han recuperado 501 tweets\n",
      "Se han eliminado los repetidos del archivo #AstraZeneca.csv , el nuevo numero de tweets es 501\n",
      "Se ha recuperado 1730 tweets en el idioma espanhol\n",
      "Se han recuperado 1219 tweets\n",
      "Se han eliminado los repetidos del archivo #Pfizer.csv , el nuevo numero de tweets es 1219\n",
      "Se ha recuperado 269 tweets en el idioma espanhol\n",
      "Se han recuperado 236 tweets\n",
      "Se han eliminado los repetidos del archivo #delta.csv , el nuevo numero de tweets es 236\n",
      "Se ha recuperado 78 tweets en el idioma espanhol\n",
      "Se han recuperado 59 tweets\n",
      "Se han eliminado los repetidos del archivo #variante.csv , el nuevo numero de tweets es 59\n",
      "Se ha recuperado 74 tweets en el idioma espanhol\n",
      "Se han recuperado 50 tweets\n",
      "Se han eliminado los repetidos del archivo #PfizerBiontech.csv , el nuevo numero de tweets es 50\n",
      "Se ha recuperado 152 tweets en el idioma espanhol\n",
      "Se han recuperado 79 tweets\n",
      "Se han eliminado los repetidos del archivo #Moderna.csv , el nuevo numero de tweets es 79\n",
      "Se ha recuperado 65 tweets en el idioma espanhol\n",
      "Se han recuperado 40 tweets\n",
      "Se han eliminado los repetidos del archivo #CureVac.csv , el nuevo numero de tweets es 40\n",
      "Se ha recuperado 31495 tweets en total\n"
     ]
    }
   ],
   "source": [
    "#final_df = Obtener_dataset(tag_vacunacion,'Vacunacion/', 'tweet', 'spanish', 'df_vacunacion' )\n",
    "final_df = Obtener_dataset(tag_vacunacion,'Vacunacion/', 'tweet', 'spanish', 'df_vacunacion' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
