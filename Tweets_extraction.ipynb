{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_elecciones = [\"#KeikoNova\", \"#keikonuncamas\", \"#FujimoriNuncaMás\", \"#NoAKeiko\", \"#Keikino\", \"#KeikoTAPERdiendo\",\"#FuerzaPopular\", \"#ConMiVotoNoTeMetas\",\n",
    "               \"#BICENTENARIOMEJORCONSTITUCION\", \"#FujimorismoNuncaMas\",\n",
    "               \"#KeikoGolpistaYDictadora\", \"#keikonoimpugnesmiacta\", \"#KEIKOMENTIROSA\", \"#KeikoPresidenta2021\",\n",
    "               \"#KeikoPresidenta\",\"#PedroCastilloPresidente\",\"#PedroCastilloNoVa\", \"#NoAlComunismoEnElPeru\",\n",
    "               \"#NoAlTerrorismo\", \"#NoAlComunismo\",\"#LosBuenosSomosMas\",\"#pedrocastilloNICagando\", \"#PedroCastilloNoVa\", \n",
    "              \"#PedroTiraPiedras\",\"#Genocidas\",\"#KeikoPresidenta2021\",\"#KeikoFujimori\",\"#CastilloMachistayHomofobico\",\n",
    "              \"#CastilloYCerronUnSoloCorazon\",\"#EleccionesPerú2021\",\"#DefiendeTuVoto\",\"#RespetaMiVoto\",\"#LaMaldiciondelaSenoraK\",\n",
    "              \"#LaCamisetaNoSeMancha\",\"#FujimorismoNuncaMás\",\"#SegundaVuelta\", \"#EleccionesBicentenario\",\"#Elecciones2021PE\",\n",
    "               \"#PeruDecide2021\",\"#PedroCastillo\",\"#KeikoFujimori\",\"#Elecciones2021\",\"#eleccionesperu\",\"#ONPE\",\"#EleccionesPeru\", \n",
    "              \"#Elecciones2021Peru\",\"#EleccionesBicentenario\", \"#Onpe\",\"ONPE\",\"#JNE\",\"#SegundaVuelta\", \n",
    "              \"#ONPEPeru\",\"#JNEPeru\",\"#PeruLibre\",\"#PERULIBRE\",\"#TerrorismoNuncaMas\",\"#Jne\", \"#PedroCastilloTe\", \"#JNE_Peru\", '#premier', \"#Bellido\", '#gabinete',\n",
    "                \"#MirthaVasquez\", \"#AnibalTorres\", \"#VacanciaPredroCastillo\", \"#VacanciaPredroCastilloYa\", \"#Congreso\", \"#MariadelCarmenAlva\", '#Cerron', \"#KeikoNova\",\"#SegundaVuelta\",\"#PedroCastilloTe\",'#NoAlNarcoEstado','#RespetaMiVoto',\n",
    "       '#KeikoPresidenta','#FujimafiaNuncaMas',\"#pedrocastilloNiCagando\",'#KEIKOMENTIROSA',\n",
    "       '#PedroCastilloNoVa','#DefiendeTuVoto','#DefiendeTuVoto','#PedroCastilloPresidente',\n",
    "       '#keikonuncamas','#BICENTENARIOMEJORCONSTITUCION','#NoAKeiko','#KeikoTAPERdiendo','#CastilloYCerronUnSoloCorazon',\n",
    "       '#NoalTerrorismo','#KeikoGolpistaYDictadora','#NoAlComunismoEnElPeru','#PeruDecide2021',\n",
    "       '#FujimoriNuncaMas','#LosBuenosSomosMas','#KeikoFujimori','#FujimorismoNuncaMas','#Genocidas',\n",
    "       '#NoAlComunismo','#PeruLibre','#PedroCastillo','#Elecciones2021','#TerrorismoNuncaMas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_tweet1 = [\"#KeikoNova\",\"#SegundaVuelta\",\"#PedroCastilloTe\",'#NoAlNarcoEstado','#RespetaMiVoto',\n",
    "       '#KeikoPresidenta','#FujimafiaNuncaMas',\"#pedrocastilloNiCagando\",'#KEIKOMENTIROSA',\n",
    "       '#PedroCastilloNoVa','#DefiendeTuVoto','#DefiendeTuVoto','#PedroCastilloPresidente',\n",
    "       '#keikonuncamas','#BICENTENARIOMEJORCONSTITUCION','#NoAKeiko','#KeikoTAPERdiendo','#CastilloYCerronUnSoloCorazon',\n",
    "       '#NoalTerrorismo','#KeikoGolpistaYDictadora','#NoAlComunismoEnElPeru','#PeruDecide2021',\n",
    "       '#FujimoriNuncaMas','#LosBuenosSomosMas','#KeikoFujimori','#FujimorismoNuncaMas','#Genocidas',\n",
    "       '#NoAlComunismo','#PeruLibre','#PedroCastillo','#Elecciones2021','#TerrorismoNuncaMas']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"#KeikoNova\",\"#SegundaVuelta\",\"#PedroCastilloTe\",'#NoAlNarcoEstado','#RespetaMiVoto',\n",
    "       '#KeikoPresidenta','#FujimafiaNuncaMas',\"#pedrocastilloNiCagando\",'#KEIKOMENTIROSA',\n",
    "       '#PedroCastilloNoVa','#DefiendeTuVoto','#DefiendeTuVoto','#PedroCastilloPresidente',\n",
    "       '#keikonuncamas','#BICENTENARIOMEJORCONSTITUCION','#NoAKeiko','#KeikoTAPERdiendo','#CastilloYCerronUnSoloCorazon',\n",
    "       '#NoalTerrorismo','#KeikoGolpistaYDictadora','#NoAlComunismoEnElPeru','#PeruDecide2021',\n",
    "       '#FujimoriNuncaMas','#LosBuenosSomosMas','#KeikoFujimori','#FujimorismoNuncaMas','#FujimorismoNuncaMás','#Genocidas',\n",
    "       '#NoAlComunismo','#PeruLibre','#PedroCastillo','#Elecciones2021','#TerrorismoNuncaMas','#FuerzaPopular','#FujimoriNuncaMás',\n",
    "       'KeikoFujimori','PedroCastillo','keiko','castillo','EleccionesPresidenciales2021','JNE','ONPE','Derecha','Izquierda','DebatePresidencial','#Rojos']\n",
    "\n",
    "tag_vac = ['#VacúnateYa','#COVID19', '#PongoElHombro', '#LaVacunaEsVida', '#NoBajemosLaGuardia', '#VamosaSalirAdelante', '#vacunacion',\n",
    "           '#sialavacuna', '#VacunaFest','#TodasLasVacunasSirven', '#NuevaCepa', '#Sinopharm', '#YoApoyoaBeto', '#ErnestoBustamante',\n",
    "           '#SagastiGenocida', '#VacunaCOVID19', '#SuizaLab', '#AstraZeneca', '#Pfizer', '#delta', '#variante', '#PfizerBiontech', \n",
    "           '#Moderna', '#CureVac']\n",
    "tag_vac2 = ['#VacunacionPeru',\n",
    "           '#sialavacuna', '#VacunaFest','#TodasLasVacunasSirven', '#NuevaCepa', '#Sinopharm', '#YoApoyoaBeto', '#ErnestoBustamante',\n",
    "           '#SagastiGenocida', '#VacunaCOVID19', '#SuizaLab', '#AstraZeneca', '#Pfizer', '#delta', '#variante', '#PfizerBiontech', \n",
    "           '#Moderna', '#CureVac']\n",
    "tag_vac1 = ['#VacunateYa']\n",
    "tag2 = ['#MirthaVásquez','#Premier','#GabineteVásquez' ,'#GuidoBellido','@patriciagamarra']\n",
    "tag_vacunacion = [\"#VacunacionPeru\", \"#MinisterioDeSaludPerú\",  \"#VacunaCOVID19\", '#VacúnateYa', '#COVID19', '#Vacunación', 'Vacunagate', \n",
    "                  '#VacúnateYa','#COVID19', '#PongoElHombro', '#LaVacunaEsVida', '#NoBajemosLaGuardia', '#VamosaSalirAdelante', '#vacunacion',\n",
    "           '#sialavacuna', '#VacunaFest','#TodasLasVacunasSirven', '#NuevaCepa', '#Sinopharm', '#ErnestoBustamante',\n",
    "           '#SagastiGenocida', '#SuizaLab', '#AstraZeneca', '#Pfizer', '#delta', '#variante', '#PfizerBiontech', \n",
    "           '#Moderna', '#CureVac']\n",
    "tag_vacunacion_1 = ['#NoBajemosLaGuardia', '#VamosaSalirAdelante', '#vacunacion',\n",
    "           '#sialavacuna', '#VacunaFest','#TodasLasVacunasSirven', '#NuevaCepa', '#Sinopharm', '#ErnestoBustamante',\n",
    "           '#SagastiGenocida', '#SuizaLab', '#AstraZeneca', '#Pfizer', '#delta', '#variante', '#PfizerBiontech', \n",
    "           '#Moderna', '#CureVac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crear_carpeta(Rutabase, name_carpeta):\n",
    "    # Se define el nombre de la carpeta o directorio a crear\n",
    "    directorio = Rutabase + name_carpeta\n",
    "    if os.path.exists(directorio):\n",
    "        shutil.rmtree(directorio)\n",
    "        os.makedirs(directorio)\n",
    "        print(\"Se reemplazo el directorio %s \" % directorio)\n",
    "    else:\n",
    "        try:\n",
    "            os.mkdir(directorio)\n",
    "        except OSError:\n",
    "            print(\"La creación del directorio %s falló\" % directorio)\n",
    "        else:\n",
    "            print(\"Se ha creado el directorio: %s \" % directorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Buscar_Palabra(cadena, palabra_incluida):\n",
    "    lista_cadenas = [cadena]\n",
    "    #print(cadena.find(palabra_incluida))\n",
    "    if cadena.find(palabra_incluida) < 0:\n",
    "        lista_cadenas.append(palabra_incluida)\n",
    "    return lista_cadenas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tweets(i, since, until):\n",
    "    print('entre', i)\n",
    "    tag = Buscar_Palabra(i,'Peru')\n",
    "    c = twint.Config()\n",
    "    print(tag)\n",
    "    c.Search = tag\n",
    "    c.Language = 'es'\n",
    "    c.Since = since\n",
    "    c.Until = until\n",
    "    c.Limit = 10000\n",
    "    c.Pandas = True\n",
    "    c.Hide_output= True\n",
    "    twint.run.Search(c)\n",
    "    df_twint = twint.storage.panda.Tweets_df\n",
    "    return df_twint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Generar_Tweets(lista, Rutabase, since, until):\n",
    "    lista = pd.unique(lista)\n",
    "    numero_tweets = 0\n",
    "    for i in lista:\n",
    "        sub_df = pd.DataFrame()\n",
    "        #print(i)\n",
    "        j = 5\n",
    "        #sub_df = search_tweets(i)\n",
    "        while len(sub_df)<=5 & (j>0) :\n",
    "            sub_df = search_tweets(i, since, until)\n",
    "            j = j - 1\n",
    "            #print(j)\n",
    "            #print(len(sub_df))\n",
    "        Rutarel =  i + '.csv'\n",
    "        Rutasol = os.path.join(Rutabase, Rutarel)\n",
    "        #print(sub_df)\n",
    "        sub_df.to_csv(Rutasol, index = False)\n",
    "        #df_twint = Eliminar_Repetidos(df_twint, 'tweet', 'spanish', 0.5)\n",
    "        #print(df_twint)\n",
    "        #print(len(df_twint))\n",
    "        #numero_tweets = numero_tweets + len(sub_df)\n",
    "        \n",
    "        #print(numero_tweets)\n",
    "        print('Se ha creado correctamente el ' + i + '.csv, recuperando ' + str(len(sub_df)) + ' tweets')\n",
    "    #df_Final.to_csv(\"Tweets_prueba.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeleccionarTweets(lista, Rutabase):\n",
    "    total_df = pd.DataFrame() \n",
    "    count = 0\n",
    "    for i in lista:\n",
    "        Rutarel =  i + '.csv'\n",
    "        Rutasol = os.path.join(Rutabase, Rutarel)\n",
    "        #print(Rutasol)\n",
    "        df = pd.read_csv(Rutasol, delimiter=',')\n",
    "        #print(df)\n",
    "        new_df = df[df['language'] == 'es']\n",
    "        print('Se ha recuperado ' + str(len(new_df)) + ' tweets en el idioma espanhol')\n",
    "        new_df = new_df.reset_index(drop = True)\n",
    "        new_df = Eliminar_Repetidos(new_df, 'tweet', 'spanish', 0.5)\n",
    "        print('Se han eliminado los repetidos del archivo '+ i +'.csv'+ ' , el nuevo numero de tweets es ' + str(len(new_df)))\n",
    "        #count = count + len(df)\n",
    "        total_df = pd.concat([total_df, new_df],ignore_index=False)\n",
    "    #print(total_df.shape)\n",
    "    total_df = total_df.reset_index(drop = True)\n",
    "    print('Se ha recuperado ' + str(len(total_df)) + ' tweets en total' )\n",
    "    return total_df\n",
    "   \n",
    "#def Eliminar_Reptidos_Archivo(df):\n",
    "    \n",
    "#df[(df['date'] > '2021-04-01') & (df['date'] < '2021-10-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recuperar_Indice(lista_indices):\n",
    "    index = []\n",
    "    for i in lista_indices:\n",
    "        index.append(i[1])\n",
    "    index = pd.unique(index)\n",
    "    index = list(index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eliminar_Repetidos(df, label, language, threshold):\n",
    "    tfidf = TfidfVectorizer(stop_words = stopwords.words(language))\n",
    "    # Construct the TF-IDF matrix\n",
    "    tfidf_matrix = tfidf.fit_transform(df[label])\n",
    "    #print(shape(tfidf_matrix))\n",
    "    # Generate the cosine similarity matrix\n",
    "    cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix[:20000])\n",
    "    #print(cosine_sim)\n",
    "    #Lista que recupera los tweets\n",
    "    A = []\n",
    "    for i in range(0,len(cosine_sim)):\n",
    "        for k in range(0,len(cosine_sim)):\n",
    "            if ((k>i) and (cosine_sim[i][k] >= threshold)):\n",
    "                #print(k)\n",
    "                A.append([i,k])\n",
    "                \n",
    "    indices_tweets = Recuperar_Indice(A)\n",
    "    df = df.drop(indices_tweets)\n",
    "    #print(df)\n",
    "    df = df.reset_index(drop = True)\n",
    "    print('Se han recuperado ' + str(len(df)) + ' tweets')\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rutabase = r'C:/Users/USER/Documents/Git/SATwint/'\n",
    "Rutabase =  r'C:/Users/claud/OneDrive/Documentos/GITHUB/TESIS/Extraction_with_Twint/'\n",
    "#carpeta = 'data4/'\n",
    "def Obtener_dataset(lista_tweet, name_carpeta, label, language, name):\n",
    "    #Crear_carpeta(Rutabase, name_carpeta)\n",
    "    Ruta = Rutabase + name_carpeta\n",
    "    Generar_Tweets(lista_tweet, Ruta,'2020-01-01', '2022-04-01')\n",
    "    #df = SeleccionarTweets(lista_tweet, Ruta)\n",
    "    #print(df)\n",
    "    #df = Eliminar_Repetidos(df, label, language, 0.5)\n",
    "    #df.to_csv(name + '.csv')\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entre #KeikoNova\n",
      "['#KeikoNova', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #KeikoNova.csv, recuperando 39 tweets\n",
      "entre #keikonuncamas\n",
      "['#keikonuncamas', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #keikonuncamas.csv, recuperando 13 tweets\n",
      "entre #FujimoriNuncaMás\n",
      "['#FujimoriNuncaMás', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #FujimoriNuncaMás.csv, recuperando 20 tweets\n",
      "entre #NoAKeiko\n",
      "['#NoAKeiko', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #NoAKeiko\n",
      "['#NoAKeiko', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #NoAKeiko\n",
      "['#NoAKeiko', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #NoAKeiko\n",
      "['#NoAKeiko', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #NoAKeiko\n",
      "['#NoAKeiko', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #NoAKeiko\n",
      "['#NoAKeiko', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #NoAKeiko.csv, recuperando 12 tweets\n",
      "entre #Keikino\n",
      "['#Keikino', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Keikino.csv, recuperando 20 tweets\n",
      "entre #KeikoTAPERdiendo\n",
      "['#KeikoTAPERdiendo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #KeikoTAPERdiendo.csv, recuperando 40 tweets\n",
      "entre #FuerzaPopular\n",
      "['#FuerzaPopular', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #FuerzaPopular.csv, recuperando 71 tweets\n",
      "entre #ConMiVotoNoTeMetas\n",
      "['#ConMiVotoNoTeMetas', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #ConMiVotoNoTeMetas.csv, recuperando 18 tweets\n",
      "entre #BICENTENARIOMEJORCONSTITUCION\n",
      "['#BICENTENARIOMEJORCONSTITUCION', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #BICENTENARIOMEJORCONSTITUCION.csv, recuperando 43 tweets\n",
      "entre #FujimorismoNuncaMas\n",
      "['#FujimorismoNuncaMas', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #FujimorismoNuncaMas\n",
      "['#FujimorismoNuncaMas', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #FujimorismoNuncaMas.csv, recuperando 17 tweets\n",
      "entre #KeikoGolpistaYDictadora\n",
      "['#KeikoGolpistaYDictadora', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #KeikoGolpistaYDictadora\n",
      "['#KeikoGolpistaYDictadora', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #KeikoGolpistaYDictadora.csv, recuperando 10 tweets\n",
      "entre #keikonoimpugnesmiacta\n",
      "['#keikonoimpugnesmiacta', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #keikonoimpugnesmiacta\n",
      "['#keikonoimpugnesmiacta', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #keikonoimpugnesmiacta\n",
      "['#keikonoimpugnesmiacta', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #keikonoimpugnesmiacta.csv, recuperando 20 tweets\n",
      "entre #KEIKOMENTIROSA\n",
      "['#KEIKOMENTIROSA', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #KEIKOMENTIROSA\n",
      "['#KEIKOMENTIROSA', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #KEIKOMENTIROSA.csv, recuperando 60 tweets\n",
      "entre #KeikoPresidenta2021\n",
      "['#KeikoPresidenta2021', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #KeikoPresidenta2021\n",
      "['#KeikoPresidenta2021', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #KeikoPresidenta2021.csv, recuperando 14 tweets\n",
      "entre #KeikoPresidenta\n",
      "['#KeikoPresidenta', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #KeikoPresidenta.csv, recuperando 19 tweets\n",
      "entre #PedroCastilloPresidente\n",
      "['#PedroCastilloPresidente', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #PedroCastilloPresidente\n",
      "['#PedroCastilloPresidente', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #PedroCastilloPresidente\n",
      "['#PedroCastilloPresidente', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #PedroCastilloPresidente.csv, recuperando 19 tweets\n",
      "entre #PedroCastilloNoVa\n",
      "['#PedroCastilloNoVa', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #PedroCastilloNoVa.csv, recuperando 7 tweets\n",
      "entre #NoAlComunismoEnElPeru\n",
      "['#NoAlComunismoEnElPeru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #NoAlComunismoEnElPeru\n",
      "['#NoAlComunismoEnElPeru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #NoAlComunismoEnElPeru\n",
      "['#NoAlComunismoEnElPeru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #NoAlComunismoEnElPeru.csv, recuperando 21 tweets\n",
      "entre #NoAlTerrorismo\n",
      "['#NoAlTerrorismo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #NoAlTerrorismo.csv, recuperando 8 tweets\n",
      "entre #NoAlComunismo\n",
      "['#NoAlComunismo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #NoAlComunismo.csv, recuperando 39 tweets\n",
      "entre #LosBuenosSomosMas\n",
      "['#LosBuenosSomosMas', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #LosBuenosSomosMas.csv, recuperando 14 tweets\n",
      "entre #pedrocastilloNICagando\n",
      "['#pedrocastilloNICagando', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #pedrocastilloNICagando\n",
      "['#pedrocastilloNICagando', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #pedrocastilloNICagando\n",
      "['#pedrocastilloNICagando', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #pedrocastilloNICagando.csv, recuperando 80 tweets\n",
      "entre #PedroTiraPiedras\n",
      "['#PedroTiraPiedras', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #PedroTiraPiedras.csv, recuperando 51 tweets\n",
      "entre #Genocidas\n",
      "['#Genocidas', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Genocidas.csv, recuperando 24 tweets\n",
      "entre #KeikoFujimori\n",
      "['#KeikoFujimori', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #KeikoFujimori.csv, recuperando 36 tweets\n",
      "entre #CastilloMachistayHomofobico\n",
      "['#CastilloMachistayHomofobico', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #CastilloMachistayHomofobico.csv, recuperando 20 tweets\n",
      "entre #CastilloYCerronUnSoloCorazon\n",
      "['#CastilloYCerronUnSoloCorazon', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #CastilloYCerronUnSoloCorazon.csv, recuperando 36 tweets\n",
      "entre #EleccionesPerú2021\n",
      "['#EleccionesPerú2021', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #EleccionesPerú2021\n",
      "['#EleccionesPerú2021', 'Peru']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #EleccionesPerú2021\n",
      "['#EleccionesPerú2021', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #EleccionesPerú2021.csv, recuperando 13 tweets\n",
      "entre #DefiendeTuVoto\n",
      "['#DefiendeTuVoto', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #DefiendeTuVoto\n",
      "['#DefiendeTuVoto', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #DefiendeTuVoto\n",
      "['#DefiendeTuVoto', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #DefiendeTuVoto.csv, recuperando 20 tweets\n",
      "entre #RespetaMiVoto\n",
      "['#RespetaMiVoto', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #RespetaMiVoto\n",
      "['#RespetaMiVoto', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #RespetaMiVoto.csv, recuperando 53 tweets\n",
      "entre #LaMaldiciondelaSenoraK\n",
      "['#LaMaldiciondelaSenoraK', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #LaMaldiciondelaSenoraK.csv, recuperando 20 tweets\n",
      "entre #LaCamisetaNoSeMancha\n",
      "['#LaCamisetaNoSeMancha', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #LaCamisetaNoSeMancha\n",
      "['#LaCamisetaNoSeMancha', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #LaCamisetaNoSeMancha.csv, recuperando 3 tweets\n",
      "entre #FujimorismoNuncaMás\n",
      "['#FujimorismoNuncaMás', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #FujimorismoNuncaMás.csv, recuperando 21 tweets\n",
      "entre #SegundaVuelta\n",
      "['#SegundaVuelta', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #SegundaVuelta\n",
      "['#SegundaVuelta', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #SegundaVuelta\n",
      "['#SegundaVuelta', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #SegundaVuelta.csv, recuperando 94 tweets\n",
      "entre #EleccionesBicentenario\n",
      "['#EleccionesBicentenario', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #EleccionesBicentenario\n",
      "['#EleccionesBicentenario', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #EleccionesBicentenario\n",
      "['#EleccionesBicentenario', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #EleccionesBicentenario\n",
      "['#EleccionesBicentenario', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #EleccionesBicentenario.csv, recuperando 42 tweets\n",
      "entre #Elecciones2021PE\n",
      "['#Elecciones2021PE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #Elecciones2021PE\n",
      "['#Elecciones2021PE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Elecciones2021PE.csv, recuperando 20 tweets\n",
      "entre #PeruDecide2021\n",
      "['#PeruDecide2021']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #PeruDecide2021\n",
      "['#PeruDecide2021']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #PeruDecide2021.csv, recuperando 35 tweets\n",
      "entre #PedroCastillo\n",
      "['#PedroCastillo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #PedroCastillo.csv, recuperando 39 tweets\n",
      "entre #Elecciones2021\n",
      "['#Elecciones2021', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Elecciones2021.csv, recuperando 24 tweets\n",
      "entre #eleccionesperu\n",
      "['#eleccionesperu', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #eleccionesperu\n",
      "['#eleccionesperu', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #eleccionesperu.csv, recuperando 60 tweets\n",
      "entre #ONPE\n",
      "['#ONPE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #ONPE\n",
      "['#ONPE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #ONPE\n",
      "['#ONPE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #ONPE\n",
      "['#ONPE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #ONPE.csv, recuperando 18 tweets\n",
      "entre #EleccionesPeru\n",
      "['#EleccionesPeru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #EleccionesPeru\n",
      "['#EleccionesPeru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #EleccionesPeru\n",
      "['#EleccionesPeru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #EleccionesPeru.csv, recuperando 15 tweets\n",
      "entre #Elecciones2021Peru\n",
      "['#Elecciones2021Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #Elecciones2021Peru\n",
      "['#Elecciones2021Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #Elecciones2021Peru\n",
      "['#Elecciones2021Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Elecciones2021Peru.csv, recuperando 20 tweets\n",
      "entre #Onpe\n",
      "['#Onpe', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Onpe.csv, recuperando 18 tweets\n",
      "entre ONPE\n",
      "['ONPE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el ONPE.csv, recuperando 20 tweets\n",
      "entre #JNE\n",
      "['#JNE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #JNE.csv, recuperando 79 tweets\n",
      "entre #ONPEPeru\n",
      "['#ONPEPeru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #ONPEPeru\n",
      "['#ONPEPeru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #ONPEPeru.csv, recuperando 54 tweets\n",
      "entre #JNEPeru\n",
      "['#JNEPeru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #JNEPeru.csv, recuperando 19 tweets\n",
      "entre #PeruLibre\n",
      "['#PeruLibre']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #PeruLibre.csv, recuperando 51 tweets\n",
      "entre #PERULIBRE\n",
      "['#PERULIBRE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #PERULIBRE\n",
      "['#PERULIBRE', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #PERULIBRE.csv, recuperando 20 tweets\n",
      "entre #TerrorismoNuncaMas\n",
      "['#TerrorismoNuncaMas', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #TerrorismoNuncaMas.csv, recuperando 20 tweets\n",
      "entre #Jne\n",
      "['#Jne', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Jne.csv, recuperando 20 tweets\n",
      "entre #PedroCastilloTe\n",
      "['#PedroCastilloTe', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #PedroCastilloTe\n",
      "['#PedroCastilloTe', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #PedroCastilloTe\n",
      "['#PedroCastilloTe', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #PedroCastilloTe\n",
      "['#PedroCastilloTe', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #PedroCastilloTe.csv, recuperando 7 tweets\n",
      "entre #JNE_Peru\n",
      "['#JNE_Peru']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #JNE_Peru\n",
      "['#JNE_Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #JNE_Peru\n",
      "['#JNE_Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #JNE_Peru.csv, recuperando 31 tweets\n",
      "entre #premier\n",
      "['#premier', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #premier.csv, recuperando 9 tweets\n",
      "entre #Bellido\n",
      "['#Bellido', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #Bellido\n",
      "['#Bellido', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #Bellido\n",
      "['#Bellido', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #Bellido\n",
      "['#Bellido', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Bellido.csv, recuperando 9 tweets\n",
      "entre #gabinete\n",
      "['#gabinete', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #gabinete\n",
      "['#gabinete', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #gabinete.csv, recuperando 40 tweets\n",
      "entre #MirthaVasquez\n",
      "['#MirthaVasquez', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #MirthaVasquez.csv, recuperando 19 tweets\n",
      "entre #AnibalTorres\n",
      "['#AnibalTorres', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #AnibalTorres.csv, recuperando 20 tweets\n",
      "entre #VacanciaPredroCastillo\n",
      "['#VacanciaPredroCastillo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #VacanciaPredroCastillo\n",
      "['#VacanciaPredroCastillo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #VacanciaPredroCastillo\n",
      "['#VacanciaPredroCastillo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #VacanciaPredroCastillo\n",
      "['#VacanciaPredroCastillo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #VacanciaPredroCastillo\n",
      "['#VacanciaPredroCastillo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #VacanciaPredroCastillo\n",
      "['#VacanciaPredroCastillo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #VacanciaPredroCastillo.csv, recuperando 1 tweets\n",
      "entre #VacanciaPredroCastilloYa\n",
      "['#VacanciaPredroCastilloYa', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #VacanciaPredroCastilloYa\n",
      "['#VacanciaPredroCastilloYa', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #VacanciaPredroCastilloYa.csv, recuperando 8 tweets\n",
      "entre #Congreso\n",
      "['#Congreso', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #Congreso\n",
      "['#Congreso', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Congreso.csv, recuperando 79 tweets\n",
      "entre #MariadelCarmenAlva\n",
      "['#MariadelCarmenAlva', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #MariadelCarmenAlva\n",
      "['#MariadelCarmenAlva', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #MariadelCarmenAlva.csv, recuperando 19 tweets\n",
      "entre #Cerron\n",
      "['#Cerron', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #Cerron\n",
      "['#Cerron', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #Cerron.csv, recuperando 5 tweets\n",
      "entre #NoAlNarcoEstado\n",
      "['#NoAlNarcoEstado', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #NoAlNarcoEstado.csv, recuperando 3 tweets\n",
      "entre #FujimafiaNuncaMas\n",
      "['#FujimafiaNuncaMas', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #FujimafiaNuncaMas.csv, recuperando 6 tweets\n",
      "entre #pedrocastilloNiCagando\n",
      "['#pedrocastilloNiCagando', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #pedrocastilloNiCagando\n",
      "['#pedrocastilloNiCagando', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #pedrocastilloNiCagando.csv, recuperando 40 tweets\n",
      "entre #NoalTerrorismo\n",
      "['#NoalTerrorismo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #NoalTerrorismo\n",
      "['#NoalTerrorismo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "entre #NoalTerrorismo\n",
      "['#NoalTerrorismo', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #NoalTerrorismo.csv, recuperando 8 tweets\n",
      "entre #FujimoriNuncaMas\n",
      "['#FujimoriNuncaMas', 'Peru']\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "Se ha creado correctamente el #FujimoriNuncaMas.csv, recuperando 20 tweets\n"
     ]
    }
   ],
   "source": [
    "#final_df = Obtener_dataset(tag_vacunacion,'Vacunacion/', 'tweet', 'spanish', 'df_vacunacion' )\n",
    "final_df = Obtener_dataset(tags_elecciones,'Elecciones/', 'tweet', 'spanish', 'df_elecciones' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
