{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fd1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np  \n",
    "from copy import deepcopy\n",
    "from string import punctuation\n",
    "from random import shuffle\n",
    "from sklearn.preprocessing import scale\n",
    "import advertools as adv\n",
    "\n",
    "\n",
    "#import gensim\n",
    "#from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
    "#LabeledSentence = gensim.models.doc2vec.LabeledSentence # we'll talk about this down below\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac851bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"final_df.csv\", encoding='utf-8')\n",
    "#data.iloc[:,1:].to_csv(\"final_df_.csv\", index = False)\n",
    "data = pd.read_csv(\"final_df_.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c71424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_character(tweet, characters):\n",
    "    #characters = \"'!?\"\n",
    "    tweet = ''.join( x for x in tweet if x not in characters)\n",
    "    return tweet\n",
    "\n",
    "def extract_emojis(str): \n",
    "    return ''.join(c for c in str if c in emoji.UNICODE_EMOJI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49ff534c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ðŸ“º']\n"
     ]
    }
   ],
   "source": [
    "#text_list = \"ðŸ¤” ðŸ™ˆ me asÃ­, bla es se ðŸ˜Œ ds ðŸ’•ðŸ‘­ðŸ‘™\"\n",
    "text_list  =  \"ðŸ‡µðŸ‡ª ADELANTO ðŸ“º | Â«[@KeikoFujimori] estÃ¡ demostrando al #PerÃº entero y al mundo que no sabe perder y no sabe aceptar su derrota\"\n",
    "emoji_summary = adv.extract_emoji(text_list)\n",
    "print(emoji_summary['emoji_flat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9289c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to retunr specific persons\n",
    "def clean_tweet(df, label_tweet, characters):\n",
    "    df['tweet_'] = df.apply(lambda x: remove_character(x[label_tweet], characters), axis=1)\n",
    "    return df\n",
    "\n",
    "#A = clean_tweet(data, 'tweet', '@#')\n",
    "#A[['tweet', 'tweet_']]\n",
    "def extract_components(tweet):\n",
    "    subject = []\n",
    "    emoticons = []\n",
    "    tweet  = str(tweet).lower()\n",
    "    #tweet = remove_character(tweet,'@#')\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    subjects = list(filter(lambda t: t.startswith('@'), tokens))\n",
    "    \n",
    "    emoji = adv.extract_emoji(tweet)\n",
    "    emoticons = emoji['emoji_flat']\n",
    "    #print(subjects, emoticons)\n",
    "    return subjects, emoticons\n",
    "    \n",
    "def extract_labels(df, label_tweet):\n",
    "    #print(df.apply(lambda x: print(extract_components(x[label_tweet])), axis=1))\n",
    "    df['subject'] = df.apply(lambda x: extract_components(x[label_tweet])[0], axis=1)\n",
    "    df['emoticons'] = df.apply(lambda x: extract_components(x[label_tweet])[1], axis=1)\n",
    "    return df\n",
    "          \n",
    "df_tweets = extract_labels(data, 'tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ab5aa68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionando las columnas mas importantes\n",
    "df_tweets = df_tweets[['id', 'date', 'tweet', 'language', 'hashtags', 'user_id', 'username', 'name', 'retweet', 'nlikes', 'nreplies', 'subject', 'emoticons']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1cc5a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "def remove_usernames_links(tweet):\n",
    "    #tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    tweet = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    tweet = remove_emojis(tweet)\n",
    "    #print(tweet)\n",
    "    return tweet\n",
    "#df['tweet'] = df['tweet'].apply(remove_usernames_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8acd2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_clean_tweets(df, label):\n",
    "    #print(df)\n",
    "    df['tweets_clean'] = df.apply(lambda x: remove_usernames_links(x[label]), axis=1)\n",
    "    return df\n",
    "    #df['tweets_clean'] = df.apply(lambda x: strip_all_entities(x[label]), axis=1)\n",
    "    \n",
    "df_tweets = pre_clean_tweets(df_tweets,'tweet')\n",
    "#df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "19c514da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.to_csv('df_v1.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
